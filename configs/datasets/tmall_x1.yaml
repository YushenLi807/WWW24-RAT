tmall_x1_001: # sampled, w/o time info
    data_format: csv
    data_root: ./data/
    feature_cols:
    - {active: false, dtype: str, name: time_stamp, type: categorical}
    -   active: true
        dtype: str
        name: [user_id, item_id, cat_id, seller_id, brand_id, action_type, age_range, gender]
        type: categorical
    label_col: {dtype: float, name: label}
    min_categr_count: 2
    train_data: ["./data/tmall_sampled/train.csv", "./data/tmall_sampled/retrieval_pool.csv"]
    valid_data: ./data/tmall_sampled/test.csv
    test_data: ./data/tmall_sampled/test.csv
tmall_x1_001_retrieval: # sampled, w/o time info
    data_format: csv
    data_root: ./data/
    feature_cols:
    - {active: false, dtype: str, name: time_stamp, type: categorical}
    -   active: true
        dtype: str
        name: [user_id, item_id, cat_id, seller_id, brand_id, action_type, age_range, gender]
        type: categorical
    label_col: {dtype: float, name: label}
    min_categr_count: 2
    train_data: ./data/tmall_sampled/train.csv
    valid_data: ./data/tmall_sampled/test.csv
    test_data: ./data/tmall_sampled/test.csv
    retrieval_configs:
        used_cols: [user_id, item_id, cat_id, seller_id, brand_id]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        retrieval_pool_data: ./data/tmall_sampled/retrieval_pool.csv
        split_type: sequential # 可选： "sequential", "random", "<X>-fold"
        label_wise: false # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        # pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: true
        qry_batch_size: 2500
        db_chunk_size: 50000
        device: "cuda:1"
        topK: 5
tmall_x1_002: # full, w/o time info
    data_format: csv
    data_root: ./data/
    feature_cols:
    - {active: false, dtype: str, name: time_stamp, type: categorical}
    -   active: true
        dtype: str
        name: [user_id, item_id, cat_id, seller_id, brand_id, action_type, age_range, gender]
        type: categorical
    label_col: {dtype: float, name: label}
    min_categr_count: 2
    train_data: ["./data/tmall/train.csv", "./data/tmall/retrieval_pool.csv"]
    valid_data: ./data/tmall/test.csv
    test_data: ./data/tmall/test.csv
tmall_x1_002_retrieval: # full, w/o time info
    data_format: csv
    data_root: ./data/
    feature_cols:
    - {active: false, dtype: str, name: time_stamp, type: categorical}
    -   active: true
        dtype: str
        name: [user_id, item_id, cat_id, seller_id, brand_id, action_type, age_range, gender]
        type: categorical
    label_col: {dtype: float, name: label}
    min_categr_count: 2
    train_data: ./data/tmall/train.csv
    valid_data: ./data/tmall/test.csv
    test_data: ./data/tmall/test.csv
    retrieval_configs:
        used_cols: [user_id, item_id, cat_id, seller_id, brand_id]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        retrieval_pool_data: ./data/tmall/retrieval_pool.csv
        split_type: sequential # 可选： "sequential", "random", "<X>-fold"
        label_wise: false # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        # pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: true
        qry_batch_size: 2500
        db_chunk_size: 50000
        device: "cuda:4"
        topK: 5
tmall_x1_003: # [DEBUG] sampled, w/o time info, only train as trainset
    data_format: csv
    data_root: ./data/
    feature_cols:
    - {active: false, dtype: str, name: time_stamp, type: categorical}
    -   active: true
        dtype: str
        name: [user_id, item_id, cat_id, seller_id, brand_id, action_type, age_range, gender]
        type: categorical
    label_col: {dtype: float, name: label}
    min_categr_count: 2
    train_data: ./data/tmall_sampled/train.csv
    valid_data: ./data/tmall_sampled/test.csv
    test_data: ./data/tmall_sampled/test.csv
