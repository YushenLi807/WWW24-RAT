kkbox_x1:
    data_format: csv
    data_root: ./data/
    feature_cols:
    -   active: true
        dtype: str
        name: [msno, song_id, source_system_tab, source_screen_name, source_type,
            city, gender, registered_via, language]
        type: categorical
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: genre_ids,
        type: sequence}
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: artist_name,
        type: sequence}
    - {active: true, dtype: str, name: isrc, preprocess: extract_country_code, type: categorical}
    - {active: true, dtype: str, name: bd, preprocess: bucketize_age, type: categorical}
    label_col: {dtype: float, name: label}
    min_categr_count: 10
    test_data: ./data/kkbox_x1/test.csv
    train_data: ./data/kkbox_x1/train.csv
    valid_data: ./data/kkbox_x1/valid.csv
kkbox_x1_retrieval:
    data_format: csv
    data_root: ./data/
    feature_cols:
    -   active: true
        dtype: str
        name: [msno, song_id, source_system_tab, source_screen_name, source_type,
            city, gender, registered_via, language]
        type: categorical
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: genre_ids,
        type: sequence}
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: artist_name,
        type: sequence}
    - {active: true, dtype: str, name: isrc, preprocess: extract_country_code, type: categorical}
    - {active: true, dtype: str, name: bd, preprocess: bucketize_age, type: categorical}
    label_col: {dtype: float, name: label}
    min_categr_count: 10
    test_data: ./data/kkbox_x1/test.csv
    train_data: ./data/kkbox_x1/train.csv
    valid_data: ./data/kkbox_x1/valid.csv
    retrieval_configs:
        used_cols: [msno, song_id, source_system_tab, 
                    source_screen_name, source_type,
                    city, gender, registered_via, 
                    language, isrc, bd]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        # retrieval_pool_data: ./data/movielens1m_x1/retrieval_pool.csv
        split_type: sequential # 可选： "sequential", "random", "<X>-fold"
        label_wise: false # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: false
        qry_batch_size: 1200
        db_chunk_size: 50000
        device: "cuda:6"
        topK: 5
kkbox_x1_10fold_retrieval:
    data_format: csv
    data_root: ./data/
    feature_cols:
    -   active: true
        dtype: str
        name: [msno, song_id, source_system_tab, source_screen_name, source_type,
            city, gender, registered_via, language]
        type: categorical
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: genre_ids,
        type: sequence}
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: artist_name,
        type: sequence}
    - {active: true, dtype: str, name: isrc, preprocess: extract_country_code, type: categorical}
    - {active: true, dtype: str, name: bd, preprocess: bucketize_age, type: categorical}
    label_col: {dtype: float, name: label}
    min_categr_count: 10
    test_data: ./data/kkbox_x1/test.csv
    train_data: ./data/kkbox_x1/train.csv
    valid_data: ./data/kkbox_x1/valid.csv
    retrieval_configs:
        used_cols: [msno, song_id, source_system_tab, 
                    source_screen_name, source_type,
                    city, gender, registered_via, 
                    language, isrc, bd]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        # retrieval_pool_data: ./data/movielens1m_x1/retrieval_pool.csv
        split_type: "10-fold" # 可选： "sequential", "random", "<X>-fold"
        label_wise: false # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: true
        qry_batch_size: 2400
        db_chunk_size: 50000
        device: "cuda:5"
        topK: 5
kkbox_x1_labelwise_retrieval:
    data_format: csv
    data_root: ./data/
    feature_cols:
    -   active: true
        dtype: str
        name: [msno, song_id, source_system_tab, source_screen_name, source_type,
            city, gender, registered_via, language]
        type: categorical
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: genre_ids,
        type: sequence}
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: artist_name,
        type: sequence}
    - {active: true, dtype: str, name: isrc, preprocess: extract_country_code, type: categorical}
    - {active: true, dtype: str, name: bd, preprocess: bucketize_age, type: categorical}
    label_col: {dtype: float, name: label}
    min_categr_count: 10
    test_data: ./data/kkbox_x1/test.csv
    train_data: ./data/kkbox_x1/train.csv
    valid_data: ./data/kkbox_x1/valid.csv
    retrieval_configs:
        used_cols: [msno, song_id, source_system_tab, 
                    source_screen_name, source_type,
                    city, gender, registered_via, 
                    language, isrc, bd]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        # retrieval_pool_data: ./data/movielens1m_x1/retrieval_pool.csv
        split_type: sequential # 可选： "sequential", "random", "<X>-fold"
        label_wise: true # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: false
        qry_batch_size: 1200
        db_chunk_size: 50000
        device: "cuda:7"
        topK: 5
kkbox_x1_labelwise_10fold_retrieval:
    data_format: csv
    data_root: ./data/
    feature_cols:
    -   active: true
        dtype: str
        name: [msno, song_id, source_system_tab, source_screen_name, source_type,
            city, gender, registered_via, language]
        type: categorical
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: genre_ids,
        type: sequence}
    - {active: true, dtype: str, encoder: MaskedSumPooling, max_len: 3, name: artist_name,
        type: sequence}
    - {active: true, dtype: str, name: isrc, preprocess: extract_country_code, type: categorical}
    - {active: true, dtype: str, name: bd, preprocess: bucketize_age, type: categorical}
    label_col: {dtype: float, name: label}
    min_categr_count: 10
    test_data: ./data/kkbox_x1/test.csv
    train_data: ./data/kkbox_x1/train.csv
    valid_data: ./data/kkbox_x1/valid.csv
    retrieval_configs:
        used_cols: [msno, song_id, source_system_tab, 
                    source_screen_name, source_type,
                    city, gender, registered_via, 
                    language, isrc, bd]
        exact_match_cols: []
        # 要么显式指定retrieval_pool_data的文件名，要么设置pool_ratio，从train_data里面分离
        # retrieval_pool_data: ./data/movielens1m_x1/retrieval_pool.csv
        split_type: "10-fold" # 可选： "sequential", "random", "<X>-fold"
        label_wise: true # if true 则会有两倍的数据量，负样本取topK，正样本取topK
        pool_ratio: 0.2 # 只有当split_type不是"X-fold"的时候有效
        # 可用11G处理，有了db_chunk_size之后就不需要管db_size了
        # batch_size * db_chunk_size * field_num < 400000000
        # batch_size 要大一点，速度才快一些，跟db_chunk_size尽量均匀
        pre_retrieval: true
        # 是否及时清理显存和内存垃圾，如果是可以防止显存爆炸的问题，但是用时会变成接近2倍
        enable_clean: false
        qry_batch_size: 1000
        db_chunk_size: 50000
        device: "cuda:6"
        topK: 5
