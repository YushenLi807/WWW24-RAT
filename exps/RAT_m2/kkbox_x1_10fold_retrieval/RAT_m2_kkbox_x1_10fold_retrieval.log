2024-03-07 14:53:44,560 P1726632 INFO {
    "batch_norm": "True",
    "batch_size": "4096",
    "data_format": "csv",
    "data_root": "./data/",
    "dataset_id": "kkbox_x1_10fold_retrieval",
    "debug": "False",
    "depth": "4",
    "dim_head": "10",
    "dnn_activations": "relu",
    "dnn_hidden_units": "[400, 400, 400]",
    "dropout": "0.0",
    "emb_dropout": "0.1",
    "embedding_dim": "40",
    "embedding_regularizer": "0.0005",
    "epochs": "100",
    "every_x_epochs": "1",
    "feature_cols": "[{'active': True, 'dtype': 'str', 'name': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language'], 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'genre_ids', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'encoder': 'MaskedSumPooling', 'max_len': 3, 'name': 'artist_name', 'type': 'sequence'}, {'active': True, 'dtype': 'str', 'name': 'isrc', 'preprocess': 'extract_country_code', 'type': 'categorical'}, {'active': True, 'dtype': 'str', 'name': 'bd', 'preprocess': 'bucketize_age', 'type': 'categorical'}]",
    "gpu": "1",
    "label_col": "{'dtype': 'float', 'name': 'label'}",
    "layer_norm": "True",
    "learning_rate": "0.001",
    "loss": "binary_crossentropy",
    "metrics": "['AUC', 'logloss']",
    "min_categr_count": "10",
    "model": "RAT_m2",
    "model_id": "RAT_m2_kkbox_x1_10fold_retrieval",
    "model_root": "./exps/RAT_m2/",
    "monitor": "AUC",
    "monitor_mode": "max",
    "net_dropout": "0",
    "num_heads": "8",
    "num_workers": "3",
    "optimizer": "adam",
    "patience": "2",
    "pickle_feature_encoder": "True",
    "pool": "cls",
    "retrieval_augmented": "True",
    "retrieval_configs": "{'used_cols': ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'city', 'gender', 'registered_via', 'language', 'isrc', 'bd'], 'exact_match_cols': [], 'split_type': '10-fold', 'label_wise': False, 'pool_ratio': 0.2, 'pre_retrieval': True, 'enable_clean': True, 'qry_batch_size': 2400, 'db_chunk_size': 50000, 'device': 'cuda:5', 'topK': 5}",
    "save_best_only": "True",
    "scale_dim": "2",
    "seed": "2021",
    "shuffle": "True",
    "task": "binary_classification",
    "test_data": "./data/kkbox_x1/test.csv",
    "train_data": "./data/kkbox_x1/train.csv",
    "use_hdf5": "True",
    "use_residual": "True",
    "use_scale": "True",
    "use_wide": "True",
    "valid_data": "./data/kkbox_x1/valid.csv",
    "verbose": "1",
    "version": "pytorch"
}
2024-03-07 14:53:44,561 P1726632 INFO Set up feature encoder...
2024-03-07 14:53:44,561 P1726632 INFO Load feature_map from json: ./data/kkbox_x1_10fold_retrieval/feature_map.json
2024-03-07 14:53:44,561 P1726632 INFO Loading data...
2024-03-07 14:53:44,562 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/train.h5
2024-03-07 14:53:44,931 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_train.h5
2024-03-07 14:53:45,032 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_train.h5
2024-03-07 14:53:45,134 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_train.h5
2024-03-07 14:53:45,207 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/valid.h5
2024-03-07 14:53:45,254 P1726632 INFO 10-fold retrieval, pool file: ./data/kkbox_x1_10fold_retrieval/train.h5
2024-03-07 14:53:45,254 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/train.h5
2024-03-07 14:53:45,626 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_valid.h5
2024-03-07 14:53:45,640 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_valid.h5
2024-03-07 14:53:45,654 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_valid.h5
2024-03-07 14:53:45,665 P1726632 INFO Train samples: total/5901932, pos/2971724, neg/2930208, ratio/50.35%, blocks/1
2024-03-07 14:53:45,665 P1726632 INFO Validation samples: total/737743, pos/371466, neg/366277, ratio/50.35%, blocks/1
2024-03-07 14:53:45,665 P1726632 INFO Loading train data done.
2024-03-07 14:53:45,665 P1726632 INFO Loading data...
2024-03-07 14:53:45,666 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/test.h5
2024-03-07 14:53:45,712 P1726632 INFO 10-fold retrieval, pool file: ./data/kkbox_x1_10fold_retrieval/train.h5
2024-03-07 14:53:45,712 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/train.h5
2024-03-07 14:53:46,077 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_test.h5
2024-03-07 14:53:46,093 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_test.h5
2024-03-07 14:53:46,108 P1726632 INFO Loading data from h5: ./data/kkbox_x1_10fold_retrieval/retrieval_5_test.h5
2024-03-07 14:53:46,120 P1726632 INFO Test samples: total/737743, pos/371466, neg/366277, ratio/50.35%, blocks/1
2024-03-07 14:53:46,120 P1726632 INFO Loading test data done.
2024-03-07 14:53:48,627 P1726632 INFO Total number of parameters: 4714649.
2024-03-07 14:53:48,628 P1726632 INFO Start training: 1441 batches/epoch
2024-03-07 14:53:48,628 P1726632 INFO ************ Epoch=1 start ************
2024-03-07 15:05:23,903 P1726632 INFO [Metrics] AUC: 0.815844 - logloss: 0.523757
2024-03-07 15:05:23,904 P1726632 INFO Save best model: monitor(max): 0.815844
2024-03-07 15:05:23,942 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 15:05:24,005 P1726632 INFO Train loss: 0.602301
2024-03-07 15:05:24,006 P1726632 INFO ************ Epoch=1 end ************
2024-03-07 15:16:54,507 P1726632 INFO [Metrics] AUC: 0.821838 - logloss: 0.518380
2024-03-07 15:16:54,508 P1726632 INFO Save best model: monitor(max): 0.821838
2024-03-07 15:16:54,579 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 15:16:54,661 P1726632 INFO Train loss: 0.579018
2024-03-07 15:16:54,662 P1726632 INFO ************ Epoch=2 end ************
2024-03-07 15:28:21,573 P1726632 INFO [Metrics] AUC: 0.826287 - logloss: 0.511723
2024-03-07 15:28:21,574 P1726632 INFO Save best model: monitor(max): 0.826287
2024-03-07 15:28:21,647 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 15:28:21,728 P1726632 INFO Train loss: 0.574400
2024-03-07 15:28:21,728 P1726632 INFO ************ Epoch=3 end ************
2024-03-07 15:39:47,762 P1726632 INFO [Metrics] AUC: 0.828225 - logloss: 0.509177
2024-03-07 15:39:47,763 P1726632 INFO Save best model: monitor(max): 0.828225
2024-03-07 15:39:47,833 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 15:39:47,918 P1726632 INFO Train loss: 0.571311
2024-03-07 15:39:47,918 P1726632 INFO ************ Epoch=4 end ************
2024-03-07 15:51:15,830 P1726632 INFO [Metrics] AUC: 0.830205 - logloss: 0.506670
2024-03-07 15:51:15,833 P1726632 INFO Save best model: monitor(max): 0.830205
2024-03-07 15:51:15,904 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 15:51:15,989 P1726632 INFO Train loss: 0.569348
2024-03-07 15:51:15,990 P1726632 INFO ************ Epoch=5 end ************
2024-03-07 16:02:43,392 P1726632 INFO [Metrics] AUC: 0.831969 - logloss: 0.503471
2024-03-07 16:02:43,393 P1726632 INFO Save best model: monitor(max): 0.831969
2024-03-07 16:02:43,464 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 16:02:43,548 P1726632 INFO Train loss: 0.569458
2024-03-07 16:02:43,548 P1726632 INFO ************ Epoch=6 end ************
2024-03-07 16:14:10,277 P1726632 INFO [Metrics] AUC: 0.833357 - logloss: 0.501826
2024-03-07 16:14:10,278 P1726632 INFO Save best model: monitor(max): 0.833357
2024-03-07 16:14:10,352 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 16:14:10,435 P1726632 INFO Train loss: 0.568913
2024-03-07 16:14:10,436 P1726632 INFO ************ Epoch=7 end ************
2024-03-07 16:25:46,285 P1726632 INFO [Metrics] AUC: 0.834609 - logloss: 0.500253
2024-03-07 16:25:46,286 P1726632 INFO Save best model: monitor(max): 0.834609
2024-03-07 16:25:46,368 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 16:25:46,464 P1726632 INFO Train loss: 0.567385
2024-03-07 16:25:46,465 P1726632 INFO ************ Epoch=8 end ************
2024-03-07 16:37:20,489 P1726632 INFO [Metrics] AUC: 0.835245 - logloss: 0.501147
2024-03-07 16:37:20,489 P1726632 INFO Save best model: monitor(max): 0.835245
2024-03-07 16:37:20,560 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 16:37:20,672 P1726632 INFO Train loss: 0.565981
2024-03-07 16:37:20,673 P1726632 INFO ************ Epoch=9 end ************
2024-03-07 16:48:50,660 P1726632 INFO [Metrics] AUC: 0.835758 - logloss: 0.499010
2024-03-07 16:48:50,661 P1726632 INFO Save best model: monitor(max): 0.835758
2024-03-07 16:48:50,732 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 16:48:50,840 P1726632 INFO Train loss: 0.564816
2024-03-07 16:48:50,840 P1726632 INFO ************ Epoch=10 end ************
2024-03-07 17:00:19,426 P1726632 INFO [Metrics] AUC: 0.836285 - logloss: 0.497806
2024-03-07 17:00:19,427 P1726632 INFO Save best model: monitor(max): 0.836285
2024-03-07 17:00:19,493 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:00:19,608 P1726632 INFO Train loss: 0.564196
2024-03-07 17:00:19,608 P1726632 INFO ************ Epoch=11 end ************
2024-03-07 17:11:51,189 P1726632 INFO [Metrics] AUC: 0.836977 - logloss: 0.497045
2024-03-07 17:11:51,189 P1726632 INFO Save best model: monitor(max): 0.836977
2024-03-07 17:11:51,273 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:11:51,389 P1726632 INFO Train loss: 0.563407
2024-03-07 17:11:51,389 P1726632 INFO ************ Epoch=12 end ************
2024-03-07 17:23:21,148 P1726632 INFO [Metrics] AUC: 0.837179 - logloss: 0.496744
2024-03-07 17:23:21,149 P1726632 INFO Save best model: monitor(max): 0.837179
2024-03-07 17:23:21,219 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:23:21,290 P1726632 INFO Train loss: 0.562377
2024-03-07 17:23:21,290 P1726632 INFO ************ Epoch=13 end ************
2024-03-07 17:34:50,102 P1726632 INFO [Metrics] AUC: 0.838093 - logloss: 0.495772
2024-03-07 17:34:50,102 P1726632 INFO Save best model: monitor(max): 0.838093
2024-03-07 17:34:50,193 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:34:50,278 P1726632 INFO Train loss: 0.561764
2024-03-07 17:34:50,278 P1726632 INFO ************ Epoch=14 end ************
2024-03-07 17:46:18,135 P1726632 INFO [Metrics] AUC: 0.838119 - logloss: 0.495494
2024-03-07 17:46:18,136 P1726632 INFO Save best model: monitor(max): 0.838119
2024-03-07 17:46:18,208 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:46:18,289 P1726632 INFO Train loss: 0.561181
2024-03-07 17:46:18,290 P1726632 INFO ************ Epoch=15 end ************
2024-03-07 17:57:46,979 P1726632 INFO [Metrics] AUC: 0.838440 - logloss: 0.495071
2024-03-07 17:57:46,980 P1726632 INFO Save best model: monitor(max): 0.838440
2024-03-07 17:57:47,072 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 17:57:47,155 P1726632 INFO Train loss: 0.560556
2024-03-07 17:57:47,155 P1726632 INFO ************ Epoch=16 end ************
2024-03-07 18:09:15,022 P1726632 INFO [Metrics] AUC: 0.838687 - logloss: 0.495000
2024-03-07 18:09:15,022 P1726632 INFO Save best model: monitor(max): 0.838687
2024-03-07 18:09:15,093 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 18:09:15,167 P1726632 INFO Train loss: 0.559755
2024-03-07 18:09:15,168 P1726632 INFO ************ Epoch=17 end ************
2024-03-07 18:20:43,503 P1726632 INFO [Metrics] AUC: 0.838529 - logloss: 0.494986
2024-03-07 18:20:43,504 P1726632 INFO Monitor(max) STOP: 0.838529 !
2024-03-07 18:20:43,504 P1726632 INFO Reduce learning rate on plateau: 0.000100
2024-03-07 18:20:43,505 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 18:20:43,607 P1726632 INFO Train loss: 0.559173
2024-03-07 18:20:43,608 P1726632 INFO ************ Epoch=18 end ************
2024-03-07 18:32:12,165 P1726632 INFO [Metrics] AUC: 0.848576 - logloss: 0.481961
2024-03-07 18:32:12,165 P1726632 INFO Save best model: monitor(max): 0.848576
2024-03-07 18:32:12,242 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 18:32:12,319 P1726632 INFO Train loss: 0.509868
2024-03-07 18:32:12,319 P1726632 INFO ************ Epoch=19 end ************
2024-03-07 18:43:41,165 P1726632 INFO [Metrics] AUC: 0.849688 - logloss: 0.481581
2024-03-07 18:43:41,169 P1726632 INFO Save best model: monitor(max): 0.849688
2024-03-07 18:43:41,240 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 18:43:41,327 P1726632 INFO Train loss: 0.478823
2024-03-07 18:43:41,327 P1726632 INFO ************ Epoch=20 end ************
2024-03-07 18:55:09,820 P1726632 INFO [Metrics] AUC: 0.848961 - logloss: 0.485109
2024-03-07 18:55:09,821 P1726632 INFO Monitor(max) STOP: 0.848961 !
2024-03-07 18:55:09,821 P1726632 INFO Reduce learning rate on plateau: 0.000010
2024-03-07 18:55:09,822 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 18:55:09,901 P1726632 INFO Train loss: 0.464707
2024-03-07 18:55:09,901 P1726632 INFO ************ Epoch=21 end ************
2024-03-07 19:06:38,157 P1726632 INFO [Metrics] AUC: 0.844967 - logloss: 0.501703
2024-03-07 19:06:38,158 P1726632 INFO Monitor(max) STOP: 0.844967 !
2024-03-07 19:06:38,158 P1726632 INFO Reduce learning rate on plateau: 0.000001
2024-03-07 19:06:38,158 P1726632 INFO Early stopping at epoch=22
2024-03-07 19:06:38,159 P1726632 INFO --- 1441/1441 batches finished ---
2024-03-07 19:06:38,248 P1726632 INFO Train loss: 0.435447
2024-03-07 19:06:38,248 P1726632 INFO Training finished.
2024-03-07 19:06:38,249 P1726632 INFO Load best model: /data1/wangjinpeng/liyusheng/RAT/exps/RAT_m2/kkbox_x1_10fold_retrieval/RAT_m2_kkbox_x1_10fold_retrieval.model
2024-03-07 19:06:38,355 P1726632 INFO ****** Validation evaluation ******
2024-03-07 19:06:57,990 P1726632 INFO [Metrics] AUC: 0.849688 - logloss: 0.481581
2024-03-07 19:06:58,186 P1726632 INFO ******** Test evaluation ********
2024-03-07 19:07:17,893 P1726632 INFO [Metrics] AUC: 0.849994 - logloss: 0.481199
